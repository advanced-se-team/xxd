{"type": "text", "bbox": [289, 1261, 1804, 3522], "res": [{"text": "oiae", "confidence": 0.40467822551727295, "text_region": [[654.0, 1275.0], [833.0, 1275.0], [833.0, 1292.0], [654.0, 1292.0]]}, {"text": "iepaiArN)a", "confidence": 0.7211018800735474, "text_region": [[1141.0, 1270.0], [1496.0, 1268.0], [1496.0, 1292.0], [1141.0, 1294.0]]}, {"text": "Meip", "confidence": 0.5042624473571777, "text_region": [[1705.0, 1270.0], [1790.0, 1270.0], [1790.0, 1294.0], [1705.0, 1294.0]]}, {"text": "developers automatically patch software bugs. However, current", "confidence": 0.999256432056427, "text_region": [[296.0, 1308.0], [1797.0, 1310.0], [1797.0, 1360.0], [296.0, 1358.0]]}, {"text": "state-of-the-art traditional and learning-based APR techniques", "confidence": 0.9873771071434021, "text_region": [[292.0, 1362.0], [1797.0, 1369.0], [1797.0, 1424.0], [291.0, 1416.0]]}, {"text": "face the problem of limited patch variety, failing to fix com-", "confidence": 0.9790217280387878, "text_region": [[291.0, 1423.0], [1797.0, 1428.0], [1797.0, 1482.0], [291.0, 1478.0]]}, {"text": "plicated bugs. This is mainly due to the reliance on bug-fixing", "confidence": 0.9906964302062988, "text_region": [[296.0, 1487.0], [1797.0, 1489.0], [1797.0, 1539.0], [296.0, 1537.0]]}, {"text": "datasets to craft fix templates (traditional) or directly predict", "confidence": 0.9730392694473267, "text_region": [[298.0, 1548.0], [1792.0, 1548.0], [1792.0, 1595.0], [298.0, 1595.0]]}, {"text": "potential patches (learning-based). Large Pre-Trained Language", "confidence": 0.9898484349250793, "text_region": [[294.0, 1605.0], [1799.0, 1607.0], [1799.0, 1664.0], [294.0, 1661.0]]}, {"text": "Models (LLMs), trained using billions of text/code tokens, can", "confidence": 0.9846459031105042, "text_region": [[294.0, 1661.0], [1802.0, 1666.0], [1802.0, 1720.0], [294.0, 1716.0]]}, {"text": "potentially help avoid this issue. Very recently, researchers have", "confidence": 0.9835943579673767, "text_region": [[298.0, 1730.0], [1797.0, 1730.0], [1797.0, 1777.0], [298.0, 1777.0]]}, {"text": "directly leveraged LLMs for APR without relying on any bug-", "confidence": 0.985558032989502, "text_region": [[296.0, 1784.0], [1797.0, 1786.0], [1797.0, 1843.0], [296.0, 1840.0]]}, {"text": "fixing datasets. Meanwhile, such existing work either failed to", "confidence": 0.9982275366783142, "text_region": [[294.0, 1845.0], [1802.0, 1843.0], [1802.0, 1897.0], [294.0, 1899.0]]}, {"text": "include state-of-the-art LLMs or was not evaluated on realistic", "confidence": 0.9936439990997314, "text_region": [[296.0, 1904.0], [1797.0, 1906.0], [1797.0, 1953.0], [296.0, 1951.0]]}, {"text": "datasets. Thus, the true power of modern LLMs on the important", "confidence": 0.9826467037200928, "text_region": [[294.0, 1965.0], [1802.0, 1965.0], [1802.0, 2019.0], [294.0, 2019.0]]}, {"text": "APR problem is yet to be revealed.", "confidence": 0.9895093441009521, "text_region": [[296.0, 2024.0], [1125.0, 2026.0], [1125.0, 2076.0], [296.0, 2074.0]]}, {"text": "In this work, we perform the first extensive study on directly", "confidence": 0.9899871945381165, "text_region": [[351.0, 2090.0], [1795.0, 2092.0], [1794.0, 2140.0], [351.0, 2137.0]]}, {"text": "applying LLMs for APR. We select 9 recent state-of-the-art", "confidence": 0.9644660949707031, "text_region": [[291.0, 2151.0], [1799.0, 2144.0], [1799.0, 2201.0], [292.0, 2208.0]]}, {"text": "LLMs, including both generative and infilling models, ranging", "confidence": 0.9925029873847961, "text_region": [[291.0, 2208.0], [1802.0, 2213.0], [1802.0, 2267.0], [291.0, 2262.0]]}, {"text": "from 125M to 20B in size. We designed 3 different repair settings", "confidence": 0.9947713017463684, "text_region": [[289.0, 2264.0], [1802.0, 2271.0], [1801.0, 2326.0], [289.0, 2318.0]]}, {"text": "to evaluate the different ways we can use LLMs to generate", "confidence": 0.9926404356956482, "text_region": [[294.0, 2330.0], [1799.0, 2330.0], [1799.0, 2384.0], [294.0, 2384.0]]}, {"text": "patches: 1) generate the entire patch function, 2) fill in a chunk", "confidence": 0.9787323474884033, "text_region": [[296.0, 2394.0], [1797.0, 2394.0], [1797.0, 2441.0], [296.0, 2441.0]]}, {"text": "of code given the prefix and suffix 3) output a single line fix.", "confidence": 0.971772313117981, "text_region": [[298.0, 2453.0], [1795.0, 2453.0], [1795.0, 2500.0], [298.0, 2500.0]]}, {"text": "We apply the LLMs under these repair settings on 5 datasets", "confidence": 0.9777435064315796, "text_region": [[296.0, 2509.0], [1802.0, 2509.0], [1802.0, 2563.0], [296.0, 2563.0]]}, {"text": "across 3 different languages and compare different LLMs in the", "confidence": 0.9823388457298279, "text_region": [[291.0, 2566.0], [1802.0, 2568.0], [1802.0, 2625.0], [291.0, 2622.0]]}, {"text": "number of bugs fixed, generation speed and compilation rate.", "confidence": 0.9909535050392151, "text_region": [[296.0, 2629.0], [1795.0, 2632.0], [1794.0, 2681.0], [296.0, 2679.0]]}, {"text": "We also compare the LLMs against recent state-of-the-art APR", "confidence": 0.9812993407249451, "text_region": [[296.0, 2691.0], [1797.0, 2688.0], [1797.0, 2738.0], [296.0, 2740.0]]}, {"text": "tools. Our study demonstrates that directly applying state-of-", "confidence": 0.9976291656494141, "text_region": [[296.0, 2749.0], [1797.0, 2749.0], [1797.0, 2804.0], [296.0, 2804.0]]}, {"text": "the-art LLMs can already substantially outperform all existing", "confidence": 0.9846568703651428, "text_region": [[294.0, 2808.0], [1797.0, 2813.0], [1797.0, 2860.0], [294.0, 2855.0]]}, {"text": "APR techniques on all our datasets. Among the studied LLMs.", "confidence": 0.9898768067359924, "text_region": [[294.0, 2867.0], [1795.0, 2872.0], [1794.0, 2919.0], [294.0, 2914.0]]}, {"text": "the scaling effect exists for APR where larger models tend to", "confidence": 0.9776405096054077, "text_region": [[296.0, 2931.0], [1799.0, 2931.0], [1799.0, 2978.0], [296.0, 2978.0]]}, {"text": "achieve better performance. Also, we show for the first time", "confidence": 0.9829344153404236, "text_region": [[296.0, 2987.0], [1797.0, 2990.0], [1797.0, 3037.0], [296.0, 3034.0]]}, {"text": "that suffix code after the buggy line (adopted in infilling-style", "confidence": 0.9887750744819641, "text_region": [[294.0, 3049.0], [1799.0, 3049.0], [1799.0, 3103.0], [294.0, 3103.0]]}, {"text": "APR) is important in not only generating more fixes but more", "confidence": 0.9896124005317688, "text_region": [[294.0, 3107.0], [1802.0, 3107.0], [1802.0, 3162.0], [294.0, 3162.0]]}, {"text": "patches with higher compilation rate. Besides patch generation,", "confidence": 0.9986218810081482, "text_region": [[294.0, 3166.0], [1797.0, 3166.0], [1797.0, 3221.0], [294.0, 3221.0]]}, {"text": "the LLMs consider correct patches to be more natural than other", "confidence": 0.9844750165939331, "text_region": [[298.0, 3230.0], [1795.0, 3230.0], [1795.0, 3277.0], [298.0, 3277.0]]}, {"text": "ones, and can even be leveraged for effective patch ranking or", "confidence": 0.9882054328918457, "text_region": [[296.0, 3286.0], [1802.0, 3286.0], [1802.0, 3341.0], [296.0, 3341.0]]}, {"text": "patch correctness checking. Lastly, we show that LLM-based", "confidence": 0.9830625057220459, "text_region": [[296.0, 3348.0], [1799.0, 3345.0], [1799.0, 3395.0], [296.0, 3397.0]]}, {"text": "APR can be further substantially boosted via: 1) increasing the", "confidence": 0.9795582890510559, "text_region": [[294.0, 3404.0], [1799.0, 3407.0], [1799.0, 3454.0], [294.0, 3451.0]]}, {"text": "sample size, and 2) incorporating fix template information.", "confidence": 0.9692965745925903, "text_region": [[301.0, 3470.0], [1679.0, 3470.0], [1679.0, 3510.0], [301.0, 3510.0]]}], "img_idx": 0}
{"type": "text", "bbox": [1862, 1246, 3374, 4313], "res": [{"text": "Repair (APR) tools have been built to automatically generate", "confidence": 0.9936012625694275, "text_region": [[1871.0, 1249.0], [3368.0, 1249.0], [3368.0, 1304.0], [1871.0, 1304.0]]}, {"text": "potential patches given the original buggy program [6].", "confidence": 0.99504554271698, "text_region": [[1868.0, 1316.0], [3232.0, 1316.0], [3232.0, 1380.0], [1868.0, 1380.0]]}, {"text": "Among traditional APR techniques [7]-[18], template-basec", "confidence": 0.9864530563354492, "text_region": [[1938.0, 1390.0], [3365.0, 1390.0], [3365.0, 1444.0], [1938.0, 1444.0]]}, {"text": "APR has been widely recognized as the state of the art [19]", "confidence": 0.9887242913246155, "text_region": [[1878.0, 1460.0], [3365.0, 1460.0], [3365.0, 1514.0], [1878.0, 1514.0]]}, {"text": "20]. 'These techniques leverage fix templates, often designec", "confidence": 0.9668285846710205, "text_region": [[1884.0, 1540.0], [3365.0, 1540.0], [3365.0, 1585.0], [1884.0, 1585.0]]}, {"text": "by human experts, to fix specific types of bugs in the source", "confidence": 0.9849791526794434, "text_region": [[1875.0, 1607.0], [3368.0, 1607.0], [3368.0, 1661.0], [1875.0, 1661.0]]}, {"text": "code. As a result, these APR tools are constrained by the", "confidence": 0.9949906468391418, "text_region": [[1875.0, 1677.0], [3368.0, 1677.0], [3368.0, 1732.0], [1875.0, 1732.0]]}, {"text": "underlying fix templates in the types of bugs that can be", "confidence": 0.9843941926956177, "text_region": [[1868.0, 1744.0], [3373.0, 1741.0], [3373.0, 1805.0], [1868.0, 1808.0]]}, {"text": "fixed. To combat this, researchers have proposed learning-", "confidence": 0.9908012747764587, "text_region": [[1872.0, 1808.0], [3368.0, 1818.0], [3367.0, 1882.0], [1871.0, 1872.0]]}, {"text": "based APR tools [21]-[24], which typically model program", "confidence": 0.9805429577827454, "text_region": [[1868.0, 1885.0], [3371.0, 1888.0], [3371.0, 1952.0], [1868.0, 1949.0]]}, {"text": "repair as a Neural Machine Translation (NMT) problem [25]", "confidence": 0.9900016784667969, "text_region": [[1865.0, 1958.0], [3368.0, 1955.0], [3368.0, 2019.0], [1865.0, 2022.0]]}, {"text": "where the goal is to translate a buggy program into a fixed", "confidence": 0.9849500060081482, "text_region": [[1868.0, 2029.0], [3373.0, 2029.0], [3373.0, 2102.0], [1868.0, 2102.0]]}, {"text": "program. The core component of these learning-based APR", "confidence": 0.9962447881698608, "text_region": [[1865.0, 2106.0], [3371.0, 2096.0], [3371.0, 2160.0], [1865.0, 2169.0]]}, {"text": "tools is an encoder and decoder pair, where the model aims", "confidence": 0.9979034066200256, "text_region": [[1875.0, 2179.0], [3368.0, 2179.0], [3368.0, 2233.0], [1875.0, 2233.0]]}, {"text": "to capture the buggy context via the encoder and then autoree", "confidence": 0.9710111618041992, "text_region": [[1871.0, 2252.0], [3365.0, 2252.0], [3365.0, 2307.0], [1871.0, 2307.0]]}, {"text": "gressively generate the patch using the decoder. As such, these", "confidence": 0.9983885288238525, "text_region": [[1868.0, 2319.0], [3368.0, 2316.0], [3368.0, 2380.0], [1868.0, 2383.0]]}, {"text": "learning-based APR tools require supervised training datasets", "confidence": 0.9909233450889587, "text_region": [[1875.0, 2396.0], [3368.0, 2396.0], [3368.0, 2450.0], [1875.0, 2450.0]]}, {"text": "containing pairs of buggy and patched code, usually obtainec", "confidence": 0.9771892428398132, "text_region": [[1875.0, 2466.0], [3365.0, 2466.0], [3365.0, 2521.0], [1875.0, 2521.0]]}, {"text": "by mining historical bug fixes from open-source repositories", "confidence": 0.9886718392372131, "text_region": [[1865.0, 2530.0], [3368.0, 2534.0], [3368.0, 2597.0], [1865.0, 2594.0]]}, {"text": "While learning-based APR tools have shown improvements in", "confidence": 0.9951268434524536, "text_region": [[1875.0, 2610.0], [3371.0, 2610.0], [3371.0, 2664.0], [1875.0, 2664.0]]}, {"text": "both the number and variety of bugs that can be fixed [21]", "confidence": 0.9796053171157837, "text_region": [[1875.0, 2680.0], [3365.0, 2680.0], [3365.0, 2735.0], [1875.0, 2735.0]]}, {"text": "[22], they are still restricted by their training data which may", "confidence": 0.9966819286346436, "text_region": [[1875.0, 2751.0], [3365.0, 2754.0], [3364.0, 2808.0], [1875.0, 2805.0]]}, {"text": "contain unrelated commits and only contain limited bug-fix", "confidence": 0.9847323298454285, "text_region": [[1871.0, 2824.0], [3365.0, 2824.0], [3365.0, 2879.0], [1871.0, 2879.0]]}, {"text": "types, which may not generalize to unseen bug types [26].", "confidence": 0.9937741756439209, "text_region": [[1868.0, 2895.0], [3311.0, 2888.0], [3311.0, 2952.0], [1868.0, 2959.0]]}, {"text": "Recent developments in building Large Pre-Trained Lan", "confidence": 0.9938615560531616, "text_region": [[1928.0, 2965.0], [3361.0, 2962.0], [3361.0, 3025.0], [1928.0, 3029.0]]}, {"text": "guage Models (LLMs) offer an alternative solution that can", "confidence": 0.9932258129119873, "text_region": [[1868.0, 3035.0], [3371.0, 3029.0], [3371.0, 3096.0], [1868.0, 3102.0]]}, {"text": "be applied for program repair without relying on historical", "confidence": 0.9806922674179077, "text_region": [[1871.0, 3105.0], [3368.0, 3105.0], [3368.0, 3169.0], [1871.0, 3169.0]]}, {"text": "bug fixes. While LLMs are usually general-purpose tools fo1", "confidence": 0.9879946708679199, "text_region": [[1872.0, 3176.0], [3368.0, 3179.0], [3368.0, 3243.0], [1871.0, 3240.0]]}, {"text": "NLP tasks (e.g., GPT3 [27]), they have also been used for pro", "confidence": 0.9855437874794006, "text_region": [[1875.0, 3256.0], [3358.0, 3256.0], [3358.0, 3310.0], [1875.0, 3310.0]]}, {"text": "gramming languages by finetuning on code (e.g., Codex [28)", "confidence": 0.9795263409614563, "text_region": [[1868.0, 3326.0], [3368.0, 3319.0], [3368.0, 3383.0], [1868.0, 3390.0]]}, {"text": "and ChatGPT [29]). Unlike the specifically designed learning-", "confidence": 0.9873685240745544, "text_region": [[1869.0, 3386.0], [3368.0, 3396.0], [3367.0, 3463.0], [1868.0, 3453.0]]}, {"text": "based APR models, LLMs are trained in an unsupervised", "confidence": 0.9955652356147766, "text_region": [[1868.0, 3460.0], [3371.0, 3466.0], [3371.0, 3530.0], [1868.0, 3524.0]]}, {"text": "fashion using up to billions of text/code tokens and can be usec", "confidence": 0.973633885383606, "text_region": [[1875.0, 3543.0], [3368.0, 3543.0], [3368.0, 3597.0], [1875.0, 3597.0]]}, {"text": "in a variety of code tasks. Recently, AlphaRepair [26] proposes", "confidence": 0.9830157160758972, "text_region": [[1871.0, 3610.0], [3368.0, 3610.0], [3368.0, 3674.0], [1871.0, 3674.0]]}, {"text": "to leverage CodeBERT [30], a large code model pre-trained or", "confidence": 0.9706284999847412, "text_region": [[1875.0, 3687.0], [3368.0, 3687.0], [3368.0, 3741.0], [1875.0, 3741.0]]}, {"text": "millions of code snippets, directly for APR. The key insight", "confidence": 0.9805288314819336, "text_region": [[1871.0, 3754.0], [3371.0, 3754.0], [3371.0, 3818.0], [1871.0, 3818.0]]}, {"text": "from AlphaRepair is instead of learning transformations to", "confidence": 0.9885809421539307, "text_region": [[1868.0, 3824.0], [3371.0, 3827.0], [3371.0, 3885.0], [1868.0, 3882.0]]}, {"text": "go from buggy code to fixed code, we can directly use the", "confidence": 0.9826408624649048, "text_region": [[1865.0, 3895.0], [3371.0, 3885.0], [3371.0, 3958.0], [1865.0, 3968.0]]}, {"text": "model to predict what the correct code should look like giver", "confidence": 0.9741301536560059, "text_region": [[1875.0, 3971.0], [3368.0, 3971.0], [3368.0, 4025.0], [1875.0, 4025.0]]}, {"text": "its surrounding context (including both prefix and suffix), i.e.", "confidence": 0.992018461227417, "text_region": [[1875.0, 4045.0], [3365.0, 4045.0], [3365.0, 4099.0], [1875.0, 4099.0]]}, {"text": "infilling-style APR. Using this idea, AlphaRepair demonstrated", "confidence": 0.9873263239860535, "text_region": [[1875.0, 4115.0], [3368.0, 4115.0], [3368.0, 4169.0], [1875.0, 4169.0]]}, {"text": "state-of-the-art repair results without finetuning on bug fixing", "confidence": 0.9925491809844971, "text_region": [[1875.0, 4188.0], [3365.0, 4188.0], [3365.0, 4243.0], [1875.0, 4243.0]]}, {"text": "dataset. While AlphaRepair has shown improvements over", "confidence": 0.9679833054542542, "text_region": [[1872.0, 4255.0], [3371.0, 4259.0], [3371.0, 4312.0], [1871.0, 4310.0]]}], "img_idx": 0}
{"type": "text", "bbox": [288, 3759, 1801, 4310], "res": [{"text": "ubiquitous in everyday life, so do software bugs. Due to", "confidence": 0.9799614548683167, "text_region": [[299.0, 3825.0], [1796.0, 3823.0], [1796.0, 3881.0], [299.0, 3883.0]]}, {"text": "the wide-ranging adoption of software systems in fields from", "confidence": 0.9971961379051208, "text_region": [[297.0, 3898.0], [1799.0, 3898.0], [1799.0, 3956.0], [297.0, 3956.0]]}, {"text": "healthcare [1] to transportation [2], these bugs can potentially", "confidence": 0.997575044631958, "text_region": [[294.0, 3969.0], [1788.0, 3972.0], [1788.0, 4025.0], [294.0, 4022.0]]}, {"text": "cause dangerous safety issues [3] and financial losses [4]. As", "confidence": 0.9940442442893982, "text_region": [[299.0, 4044.0], [1795.0, 4041.0], [1795.0, 4092.0], [299.0, 4096.0]]}, {"text": "such, developers often need to spend a significant amount of", "confidence": 0.9934751391410828, "text_region": [[299.0, 4114.0], [1799.0, 4113.0], [1799.0, 4166.0], [299.0, 4168.0]]}, {"text": "time and effort to fix software bugs [5]. In order to help", "confidence": 0.981377124786377, "text_region": [[299.0, 4185.0], [1790.0, 4188.0], [1790.0, 4236.0], [299.0, 4233.0]]}, {"text": "developers reducethis", "confidence": 0.9781835675239563, "text_region": [[296.0, 4257.0], [873.0, 4255.0], [873.0, 4302.0], [296.0, 4304.0]]}, {"text": "s manual effort, Automated Program", "confidence": 0.9337823390960693, "text_region": [[855.0, 4258.0], [1792.0, 4258.0], [1792.0, 4301.0], [855.0, 4301.0]]}], "img_idx": 0}
{"type": "text", "bbox": [2469, 735, 2996, 1021], "res": [{"text": "Lingming", "confidence": 0.9998204708099365, "text_region": [[2508.0, 740.0], [2778.0, 746.0], [2777.0, 798.0], [2507.0, 791.0]]}, {"text": "Zhang", "confidence": 0.998684287071228, "text_region": [[2791.0, 740.0], [2958.0, 749.0], [2955.0, 794.0], [2788.0, 786.0]]}, {"text": "University of Illinois", "confidence": 0.9579187035560608, "text_region": [[2487.0, 815.0], [2988.0, 817.0], [2988.0, 868.0], [2486.0, 866.0]]}, {"text": "Urbana-Champaign", "confidence": 0.9964554309844971, "text_region": [[2500.0, 889.0], [2977.0, 898.0], [2976.0, 943.0], [2499.0, 933.0]]}, {"text": "lingming @illinois.edu", "confidence": 0.9773972034454346, "text_region": [[2472.0, 964.0], [2992.0, 961.0], [2992.0, 1009.0], [2472.0, 1012.0]]}], "img_idx": 0}
{"type": "text", "bbox": [658, 735, 1226, 1022], "res": [{"text": "Chunqiu", "confidence": 0.9955002069473267, "text_region": [[673.0, 743.0], [902.0, 743.0], [902.0, 791.0], [673.0, 791.0]]}, {"text": "Steven", "confidence": 0.9959939122200012, "text_region": [[914.0, 745.0], [1096.0, 745.0], [1096.0, 786.0], [914.0, 786.0]]}, {"text": "Xia", "confidence": 0.9976927638053894, "text_region": [[1113.0, 739.0], [1211.0, 745.0], [1209.0, 785.0], [1111.0, 780.0]]}, {"text": "University of Illinois", "confidence": 0.9587700366973877, "text_region": [[691.0, 815.0], [1193.0, 813.0], [1194.0, 867.0], [692.0, 870.0]]}, {"text": "Urbana-Champaign", "confidence": 0.9983166456222534, "text_region": [[704.0, 887.0], [1183.0, 898.0], [1182.0, 945.0], [703.0, 934.0]]}, {"text": "chunqiu2 @illinois.edu", "confidence": 0.9859541058540344, "text_region": [[671.0, 966.0], [1209.0, 964.0], [1209.0, 1008.0], [671.0, 1010.0]]}], "img_idx": 0}
{"type": "text", "bbox": [1588, 734, 2091, 1020], "res": [{"text": "Yuxiang", "confidence": 0.9988731741905212, "text_region": [[1673.0, 736.0], [1888.0, 747.0], [1886.0, 795.0], [1671.0, 785.0]]}, {"text": "Wei", "confidence": 0.9971019625663757, "text_region": [[1909.0, 742.0], [2011.0, 742.0], [2011.0, 786.0], [1909.0, 786.0]]}, {"text": "UniversityofIllinois", "confidence": 0.9599602818489075, "text_region": [[1595.0, 818.0], [2086.0, 818.0], [2086.0, 866.0], [1595.0, 866.0]]}, {"text": "Urbana-Champaign", "confidence": 0.9973583221435547, "text_region": [[1602.0, 888.0], [2081.0, 897.0], [2081.0, 944.0], [1601.0, 934.0]]}, {"text": "ywei40@illinois.edu", "confidence": 0.9941727519035339, "text_region": [[1594.0, 966.0], [2085.0, 964.0], [2085.0, 1008.0], [1594.0, 1010.0]]}], "img_idx": 0}
{"type": "title", "bbox": [631, 332, 3056, 622], "res": [{"text": "Automated Program", "confidence": 0.968941867351532, "text_region": [[642.0, 348.0], [1808.0, 357.0], [1808.0, 441.0], [641.0, 431.0]]}, {"text": "Repair in the", "confidence": 0.9594407677650452, "text_region": [[1852.0, 348.0], [2647.0, 355.0], [2646.0, 448.0], [1851.0, 440.0]]}, {"text": "e Era of", "confidence": 0.8321417570114136, "text_region": [[2606.0, 348.0], [3036.0, 348.0], [3036.0, 427.0], [2606.0, 427.0]]}, {"text": "Large", "confidence": 0.9994913339614868, "text_region": [[772.0, 494.0], [1123.0, 510.0], [1117.0, 612.0], [766.0, 596.0]]}, {"text": "Pre-trained", "confidence": 0.9994188547134399, "text_region": [[1146.0, 509.0], [1816.0, 509.0], [1816.0, 595.0], [1146.0, 595.0]]}, {"text": "I Language", "confidence": 0.8971155285835266, "text_region": [[1763.0, 508.0], [2432.0, 513.0], [2432.0, 600.0], [1762.0, 595.0]]}, {"text": "eModels", "confidence": 0.9920362830162048, "text_region": [[2376.0, 505.0], [2883.0, 499.0], [2885.0, 597.0], [2377.0, 602.0]]}, {"text": "", "confidence": 0.0, "text_region": [[1106.0, 534.0], [1154.0, 534.0], [1154.0, 572.0], [1106.0, 572.0]]}], "img_idx": 0}
{"type": "title", "bbox": [812, 3629, 1279, 3673], "res": [], "img_idx": 0}
