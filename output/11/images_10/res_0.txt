{"type": "text", "bbox": [1867, 312, 3380, 2237], "res": [{"text": "fuzzing [82], where LLMs can be potentially used to help gen-", "confidence": 0.9926291108131409, "text_region": [[1873.0, 316.0], [3364.0, 320.0], [3364.0, 368.0], [1873.0, 364.0]]}, {"text": "erate arbitrary inputs to fuzz test various software systems (in", "confidence": 0.9911364912986755, "text_region": [[1877.0, 386.0], [3364.0, 386.0], [3364.0, 440.0], [1877.0, 440.0]]}, {"text": "cluding libraries, compilers, and interpreters). Compared with", "confidence": 0.9886308908462524, "text_region": [[1875.0, 454.0], [3376.0, 452.0], [3376.0, 512.0], [1875.0, 515.0]]}, {"text": "traditional automated fuzzing techniques [83] which require", "confidence": 0.9769161939620972, "text_region": [[1873.0, 527.0], [3372.0, 529.0], [3372.0, 583.0], [1873.0, 581.0]]}, {"text": "extensive human efforts for ensuring the syntactic/semantic va-", "confidence": 0.9914934635162354, "text_region": [[1877.0, 603.0], [3370.0, 603.0], [3370.0, 651.0], [1877.0, 651.0]]}, {"text": "lidity of input generation/mutation, LLMs offer an alternative", "confidence": 0.9838627576828003, "text_region": [[1875.0, 673.0], [3372.0, 669.0], [3372.0, 721.0], [1875.0, 725.0]]}, {"text": "solution by learning from billions of available code snippets", "confidence": 0.9825647473335266, "text_region": [[1877.0, 745.0], [3376.0, 745.0], [3376.0, 799.0], [1877.0, 799.0]]}, {"text": "in the wild to generate syntactically and also semantically", "confidence": 0.9741054177284241, "text_region": [[1869.0, 811.0], [3374.0, 813.0], [3374.0, 873.0], [1869.0, 871.0]]}, {"text": "valid input programs fully automatically (as demonstrated in", "confidence": 0.9852762222290039, "text_region": [[1877.0, 888.0], [3376.0, 885.0], [3376.0, 940.0], [1877.0, 942.0]]}, {"text": "recent work [84]). LLMs can also be used to target more", "confidence": 0.9817934632301331, "text_region": [[1875.0, 960.0], [3374.0, 962.0], [3374.0, 1010.0], [1875.0, 1008.0]]}, {"text": "context dependent tasks such as test [85] or test-oracle [86]", "confidence": 0.9869691729545593, "text_region": [[1879.0, 1034.0], [3370.0, 1032.0], [3370.0, 1080.0], [1879.0, 1082.0]]}, {"text": "generation. For example, while existing learning-based test-", "confidence": 0.9861000776290894, "text_region": [[1873.0, 1104.0], [3376.0, 1100.0], [3376.0, 1154.0], [1873.0, 1158.0]]}, {"text": "oracle generation techniques [87]-[89] mainly formulate the", "confidence": 0.9763444066047668, "text_region": [[1879.0, 1178.0], [3372.0, 1178.0], [3372.0, 1226.0], [1879.0, 1226.0]]}, {"text": "problem as a classification or NMT problem, another natural", "confidence": 0.9833763837814331, "text_region": [[1877.0, 1248.0], [3372.0, 1248.0], [3372.0, 1297.0], [1877.0, 1297.0]]}, {"text": "solution could be to leverage the LLMs to directly complete", "confidence": 0.9720380902290344, "text_region": [[1877.0, 1321.0], [3372.0, 1321.0], [3372.0, 1369.0], [1877.0, 1369.0]]}, {"text": "or infill the oracles based on context information (such as", "confidence": 0.9747216701507568, "text_region": [[1873.0, 1387.0], [3378.0, 1389.0], [3378.0, 1443.0], [1873.0, 1441.0]]}, {"text": "focal method and test prefix/suffix). Similar to APR, mutation", "confidence": 0.9938616156578064, "text_region": [[1877.0, 1461.0], [3370.0, 1461.0], [3370.0, 1509.0], [1877.0, 1509.0]]}, {"text": "testing [90] or bug seeding in general [89], [91], [92] als0", "confidence": 0.9598173499107361, "text_region": [[1875.0, 1535.0], [3374.0, 1531.0], [3374.0, 1583.0], [1875.0, 1587.0]]}, {"text": "applies systematic modifications to programs under test. As", "confidence": 0.9949783682823181, "text_region": [[1879.0, 1603.0], [3374.0, 1603.0], [3374.0, 1657.0], [1879.0, 1657.0]]}, {"text": "a result, it is also very natural to directly apply infilling-style", "confidence": 0.984002411365509, "text_region": [[1871.0, 1674.0], [3372.0, 1676.0], [3372.0, 1732.0], [1871.0, 1730.0]]}, {"text": "APR techniques (such as AlphaRepair [26]) for such domains.", "confidence": 0.9818023443222046, "text_region": [[1875.0, 1746.0], [3372.0, 1748.0], [3372.0, 1802.0], [1875.0, 1800.0]]}, {"text": "In addition to these discussed SE tasks above, we believe our", "confidence": 0.9861556887626648, "text_region": [[1875.0, 1822.0], [3374.0, 1822.0], [3374.0, 1868.0], [1875.0, 1868.0]]}, {"text": "study results and techniques can also motivate, inspire, and", "confidence": 0.9864240288734436, "text_region": [[1879.0, 1894.0], [3374.0, 1894.0], [3374.0, 1942.0], [1879.0, 1942.0]]}, {"text": "be applied to many other relevant SE tasks involving code", "confidence": 0.9812257885932922, "text_region": [[1875.0, 1964.0], [3374.0, 1962.0], [3374.0, 2016.0], [1875.0, 2018.0]]}, {"text": "generation/mutation. These potential applications along with", "confidence": 0.9837508797645569, "text_region": [[1869.0, 2032.0], [3378.0, 2030.0], [3378.0, 2091.0], [1869.0, 2093.0]]}, {"text": "LLMs for APR highlight the promising future of using LLMs", "confidence": 0.9877781867980957, "text_region": [[1873.0, 2107.0], [3372.0, 2107.0], [3372.0, 2161.0], [1873.0, 2161.0]]}, {"text": "to help with SE in general.", "confidence": 0.9843289256095886, "text_region": [[1875.0, 2179.0], [2535.0, 2179.0], [2535.0, 2227.0], [1875.0, 2227.0]]}], "img_idx": 0}
{"type": "text", "bbox": [1869, 2431, 3381, 3770], "res": [{"text": "We present an extensive evaluation on LLMs for automated", "confidence": 0.9965245127677917, "text_region": [[1945.0, 2437.0], [3375.0, 2436.0], [3375.0, 2479.0], [1945.0, 2481.0]]}, {"text": "program repair. We use 9 state-of-the-art LLMs with 5 differ-", "confidence": 0.9929935336112976, "text_region": [[1878.0, 2504.0], [3371.0, 2496.0], [3372.0, 2549.0], [1879.0, 2557.0]]}, {"text": "ent repair datasets and design different practical repair settings", "confidence": 0.9950143098831177, "text_region": [[1882.0, 2567.0], [3376.0, 2571.0], [3376.0, 2633.0], [1882.0, 2629.0]]}, {"text": "to compare and contrast the repair effectiveness of different", "confidence": 0.98685622215271, "text_region": [[1875.0, 2646.0], [3376.0, 2643.0], [3376.0, 2691.0], [1875.0, 2694.0]]}, {"text": "LLMs. In our evaluation, we shed light on the scaling effect", "confidence": 0.9779358506202698, "text_region": [[1875.0, 2715.0], [3378.0, 2715.0], [3378.0, 2767.0], [1875.0, 2767.0]]}, {"text": "that increasing model size has on various important factors in", "confidence": 0.9985057711601257, "text_region": [[1877.0, 2787.0], [3373.0, 2787.0], [3373.0, 2840.0], [1877.0, 2840.0]]}, {"text": "APR such as the number of bugs fixed, the speed of patch", "confidence": 0.9884857535362244, "text_region": [[1880.0, 2860.0], [3372.0, 2865.0], [3371.0, 2911.0], [1880.0, 2907.0]]}, {"text": "generation, and the compilation rate. Also, we compare the", "confidence": 0.981805682182312, "text_region": [[1878.0, 2932.0], [3368.0, 2930.0], [3368.0, 2983.0], [1878.0, 2984.0]]}, {"text": "performance of LLMs against state-of-the-art APR tools and", "confidence": 0.9913914203643799, "text_region": [[1880.0, 3003.0], [3375.0, 3003.0], [3375.0, 3054.0], [1880.0, 3054.0]]}, {"text": "nighlight the unique fixes and advantages of using LLMs", "confidence": 0.974044919013977, "text_region": [[1882.0, 3074.0], [3373.0, 3074.0], [3373.0, 3131.0], [1882.0, 3131.0]]}, {"text": "for APR. Furthermore, we evaluated the ability for LLMs", "confidence": 0.9607741832733154, "text_region": [[1875.0, 3144.0], [3370.0, 3144.0], [3370.0, 3197.0], [1875.0, 3197.0]]}, {"text": "to perform patch ranking and patch correctness checking in", "confidence": 0.9775184392929077, "text_region": [[1872.0, 3218.0], [3376.0, 3215.0], [3376.0, 3272.0], [1872.0, 3276.0]]}, {"text": "order to prioritize correct patches for faster repair. Lastly", "confidence": 0.9829204678535461, "text_region": [[1880.0, 3288.0], [3365.0, 3291.0], [3365.0, 3342.0], [1880.0, 3339.0]]}, {"text": "we demonstrate the possibilities (i.e., increasing", "confidence": 0.9937446117401123, "text_region": [[1877.0, 3356.0], [3091.0, 3364.0], [3091.0, 3417.0], [1877.0, 3409.0]]}, {"text": "gthesample", "confidence": 0.9968360662460327, "text_region": [[3063.0, 3364.0], [3366.0, 3361.0], [3367.0, 3410.0], [3063.0, 3414.0]]}, {"text": "size and combining LLMs with repair templates) to further", "confidence": 0.9892229437828064, "text_region": [[1875.0, 3432.0], [3375.0, 3434.0], [3375.0, 3486.0], [1875.0, 3485.0]]}, {"text": "boost the performance of LLMs for APR. The results from", "confidence": 0.9815469980239868, "text_region": [[1880.0, 3507.0], [3376.0, 3505.0], [3376.0, 3553.0], [1880.0, 3555.0]]}, {"text": "our study demonstrate promising future of adopting LLMs", "confidence": 0.9786619544029236, "text_region": [[1880.0, 3578.0], [3368.0, 3578.0], [3368.0, 3631.0], [1880.0, 3631.0]]}, {"text": "for APR and beyond (e.g., other SE tasks involving program", "confidence": 0.9858143925666809, "text_region": [[1875.0, 3648.0], [3375.0, 3651.0], [3375.0, 3703.0], [1875.0, 3700.0]]}, {"text": "generation/mutation).", "confidence": 0.9958010911941528, "text_region": [[1886.0, 3722.0], [2382.0, 3722.0], [2382.0, 3764.0], [1886.0, 3764.0]]}], "img_idx": 0}
{"type": "text", "bbox": [288, 2070, 1805, 4304], "res": [{"text": "In this work, we conduct a large-scale study on directly", "confidence": 0.9956498742103577, "text_region": [[354.0, 2077.0], [1791.0, 2079.0], [1791.0, 2128.0], [354.0, 2126.0]]}, {"text": "applying LLMs for APR, one of the most important problems", "confidence": 0.9888038635253906, "text_region": [[300.0, 2147.0], [1798.0, 2147.0], [1798.0, 2203.0], [300.0, 2203.0]]}, {"text": "in Software Engineering (SE). We demonstrate not only by", "confidence": 0.9848109483718872, "text_region": [[295.0, 2217.0], [1793.0, 2217.0], [1793.0, 2272.0], [295.0, 2272.0]]}, {"text": "directly applying LLMs we can already outperform prior APR", "confidence": 0.9974408149719238, "text_region": [[295.0, 2291.0], [1795.0, 2289.0], [1796.0, 2345.0], [295.0, 2347.0]]}, {"text": "techniques studied for over a decade, but also that we can", "confidence": 0.9785247445106506, "text_region": [[297.0, 2366.0], [1795.0, 2363.0], [1796.0, 2412.0], [298.0, 2414.0]]}, {"text": "further boost LLM performance by combining domain-specific", "confidence": 0.999123215675354, "text_region": [[295.0, 2435.0], [1796.0, 2435.0], [1796.0, 2489.0], [295.0, 2489.0]]}, {"text": "techniques from SE. Building on these findings, we highlight", "confidence": 0.9949462413787842, "text_region": [[297.0, 2507.0], [1798.0, 2507.0], [1798.0, 2561.0], [297.0, 2561.0]]}, {"text": "two key directions for future work:", "confidence": 0.9836904406547546, "text_region": [[297.0, 2580.0], [1158.0, 2580.0], [1158.0, 2633.0], [297.0, 2633.0]]}, {"text": "Improving LLM performance for APR. We plan to con-", "confidence": 0.985218346118927, "text_region": [[300.0, 2666.0], [1796.0, 2666.0], [1796.0, 2719.0], [300.0, 2719.0]]}, {"text": "tinue improving the performance of LLMs for APR. One", "confidence": 0.9898675084114075, "text_region": [[297.0, 2740.0], [1793.0, 2738.0], [1793.0, 2787.0], [298.0, 2789.0]]}, {"text": "approach is to use additional information, such as project-", "confidence": 0.9832054376602173, "text_region": [[300.0, 2810.0], [1793.0, 2810.0], [1793.0, 2866.0], [300.0, 2866.0]]}, {"text": "specific knowledge (i.e., from buggy project itself following", "confidence": 0.9861177206039429, "text_region": [[295.0, 2877.0], [1800.0, 2877.0], [1800.0, 2940.0], [295.0, 2940.0]]}, {"text": "the plastic surgery hypothesis [8o]). For example, one could", "confidence": 0.9860056638717651, "text_region": [[295.0, 2954.0], [1796.0, 2954.0], [1796.0, 3010.0], [295.0, 3010.0]]}, {"text": "fine-tune/prompt the LLMs on the original buggy project to", "confidence": 0.9867500066757202, "text_region": [[295.0, 3019.0], [1798.0, 3027.0], [1798.0, 3082.0], [295.0, 3075.0]]}, {"text": "prime the model to generate code that fits the style/pattern", "confidence": 0.9853436350822449, "text_region": [[293.0, 3096.0], [1798.0, 3092.0], [1798.0, 3147.0], [293.0, 3152.0]]}, {"text": "used in the project. Another approach is to incorporate repair-", "confidence": 0.9904652833938599, "text_region": [[297.0, 3168.0], [1791.0, 3168.0], [1791.0, 3222.0], [297.0, 3222.0]]}, {"text": "specific knowledge by using additional templates as demon-", "confidence": 0.9916031956672668, "text_region": [[297.0, 3241.0], [1793.0, 3241.0], [1793.0, 3294.0], [297.0, 3294.0]]}, {"text": "strated in Section V-D to reduce the amount of code LLM", "confidence": 0.9805933833122253, "text_region": [[300.0, 3313.0], [1793.0, 3313.0], [1793.0, 3359.0], [300.0, 3359.0]]}, {"text": "has to generate and arrive at the correct patch faster. Along", "confidence": 0.9945043325424194, "text_region": [[290.0, 3378.0], [1800.0, 3380.0], [1800.0, 3443.0], [290.0, 3441.0]]}, {"text": "with these potential improvement directions, we also believe", "confidence": 0.9944251775741577, "text_region": [[300.0, 3455.0], [1798.0, 3455.0], [1798.0, 3508.0], [300.0, 3508.0]]}, {"text": "that we can use other new types of LLMs (i.e., dialogue-", "confidence": 0.9628356099128723, "text_region": [[295.0, 3524.0], [1793.0, 3524.0], [1793.0, 3578.0], [295.0, 3578.0]]}, {"text": "based) for APR such as ChatGPT [29]. ChatGPT is fine-tuned", "confidence": 0.9832974076271057, "text_region": [[295.0, 3599.0], [1800.0, 3599.0], [1800.0, 3652.0], [295.0, 3652.0]]}, {"text": "using reinforcement learning algorithm with human feedback", "confidence": 0.9843548536300659, "text_region": [[295.0, 3669.0], [1798.0, 3666.0], [1798.0, 3722.0], [295.0, 3725.0]]}, {"text": "designed for dialogues/conversations. We can leverage the", "confidence": 0.9866223931312561, "text_region": [[295.0, 3741.0], [1798.0, 3738.0], [1798.0, 3794.0], [295.0, 3797.0]]}, {"text": "currently underused testcase result to provide feedback to", "confidence": 0.9821586608886719, "text_region": [[295.0, 3813.0], [1798.0, 3811.0], [1798.0, 3864.0], [295.0, 3867.0]]}, {"text": "ChatGPT in a conversational manner, allowing the model", "confidence": 0.9713109135627747, "text_region": [[298.0, 3883.0], [1791.0, 3885.0], [1791.0, 3934.0], [297.0, 3932.0]]}, {"text": "to correct its previous mistakes and generate more correct", "confidence": 0.9814075231552124, "text_region": [[295.0, 3957.0], [1798.0, 3960.0], [1798.0, 4008.0], [295.0, 4006.0]]}, {"text": "patches[81].", "confidence": 0.9971416592597961, "text_region": [[292.0, 4027.0], [607.0, 4022.0], [608.0, 4078.0], [293.0, 4083.0]]}, {"text": "Application of LLMs for other relevant SE tasks. While we", "confidence": 0.9938403367996216, "text_region": [[297.0, 4116.0], [1795.0, 4113.0], [1796.0, 4167.0], [298.0, 4169.0]]}, {"text": "study the performance of LLMs for APR, LLMs can be used", "confidence": 0.9949997067451477, "text_region": [[295.0, 4188.0], [1803.0, 4183.0], [1803.0, 4236.0], [295.0, 4241.0]]}, {"text": "for various other software engineering tasks. One such task is", "confidence": 0.9977881908416748, "text_region": [[297.0, 4260.0], [1796.0, 4260.0], [1796.0, 4303.0], [297.0, 4303.0]]}], "img_idx": 0}
{"type": "text", "bbox": [289, 309, 1803, 1885], "res": [{"text": "Since we only have access to the training data used in", "confidence": 0.9827769994735718, "text_region": [[359.0, 316.0], [1800.0, 316.0], [1800.0, 365.0], [359.0, 365.0]]}, {"text": "CodeT5, GPT-Neo, GPT-J and GPT-NeoX models, we further", "confidence": 0.9758007526397705, "text_region": [[300.0, 383.0], [1795.0, 385.0], [1795.0, 434.0], [300.0, 432.0]]}, {"text": "check if the fixed function is within the training datasets when", "confidence": 0.9865687489509583, "text_region": [[299.0, 453.0], [1798.0, 457.0], [1798.0, 508.0], [299.0, 504.0]]}, {"text": "the correct patch is equivalent to the developer fix for these", "confidence": 0.9903412461280823, "text_region": [[299.0, 531.0], [1795.0, 531.0], [1795.0, 580.0], [299.0, 580.0]]}, {"text": "models. We found that while 38% (48/128) of bugs f", "confidence": 0.9658834338188171, "text_region": [[299.0, 598.0], [1705.0, 603.0], [1705.0, 652.0], [299.0, 647.0]]}, {"text": "fixes", "confidence": 0.8262343406677246, "text_region": [[1684.0, 609.0], [1793.0, 609.0], [1793.0, 646.0], [1684.0, 646.0]]}, {"text": "contain only the same fix as the developer patch, only 15%", "confidence": 0.9943950176239014, "text_region": [[299.0, 669.0], [1795.0, 670.0], [1795.0, 726.0], [299.0, 724.0]]}, {"text": "(20/128) of those patches are also found in the original training", "confidence": 0.9932076334953308, "text_region": [[299.0, 737.0], [1797.0, 744.0], [1796.0, 800.0], [299.0, 793.0]]}, {"text": "data, showing that the majority of correct bug fixes provided by", "confidence": 0.9829577207565308, "text_region": [[297.0, 816.0], [1793.0, 816.0], [1793.0, 870.0], [297.0, 870.0]]}, {"text": "these LLMs are not simply from memorizing the training data.", "confidence": 0.9948409199714661, "text_region": [[297.0, 885.0], [1793.0, 885.0], [1793.0, 941.0], [297.0, 941.0]]}, {"text": "Moreover, our RQ4 shows that improvements can be further", "confidence": 0.9872546792030334, "text_region": [[302.0, 959.0], [1798.0, 959.0], [1798.0, 1008.0], [302.0, 1008.0]]}, {"text": "made by combining repair templates with LLMs, which is", "confidence": 0.990821361541748, "text_region": [[299.0, 1028.0], [1801.0, 1028.0], [1801.0, 1089.0], [299.0, 1089.0]]}, {"text": "orthogonal to the data leakage issue. Additionally, We observe", "confidence": 0.9877583384513855, "text_region": [[309.0, 1105.0], [1795.0, 1105.0], [1795.0, 1154.0], [309.0, 1154.0]]}, {"text": "that LLMs are able to achieve the state-of-the-art results on", "confidence": 0.9811260104179382, "text_region": [[297.0, 1171.0], [1798.0, 1174.0], [1798.0, 1223.0], [297.0, 1220.0]]}, {"text": "QuixBugs dataset which is not part of the training", "confidence": 0.9828567504882812, "text_region": [[304.0, 1246.0], [1597.0, 1246.0], [1597.0, 1296.0], [304.0, 1296.0]]}, {"text": "dataas", "confidence": 0.9982013702392578, "text_region": [[1580.0, 1246.0], [1798.0, 1250.0], [1798.0, 1296.0], [1579.0, 1292.0]]}, {"text": "it has low number of stars on GitHub and contains synthetic", "confidence": 0.9906924366950989, "text_region": [[296.0, 1315.0], [1792.0, 1319.0], [1792.0, 1368.0], [295.0, 1365.0]]}, {"text": "bugs and patches that are not part of any larger real-world", "confidence": 0.9901068210601807, "text_region": [[302.0, 1388.0], [1793.0, 1388.0], [1793.0, 1442.0], [302.0, 1442.0]]}, {"text": "projects. Further reducing the data leakage issue would require", "confidence": 0.9885231852531433, "text_region": [[299.0, 1458.0], [1790.0, 1457.0], [1790.0, 1514.0], [299.0, 1516.0]]}, {"text": "retraining the LLMs, which could be extremely costly.", "confidence": 0.9873355031013489, "text_region": [[299.0, 1529.0], [1630.0, 1532.0], [1630.0, 1588.0], [299.0, 1585.0]]}, {"text": "External. We evaluate LLMs on 5 repair datasets across 3", "confidence": 0.9843863248825073, "text_region": [[301.0, 1616.0], [1790.0, 1621.0], [1790.0, 1670.0], [300.0, 1665.0]]}, {"text": "programming languages, making our evaluation one of the", "confidence": 0.9825506210327148, "text_region": [[299.0, 1693.0], [1795.0, 1688.0], [1795.0, 1744.0], [299.0, 1749.0]]}, {"text": "most comprehensive studies in APR. However, our findings", "confidence": 0.9872037172317505, "text_region": [[300.0, 1764.0], [1796.0, 1764.0], [1796.0, 1818.0], [300.0, 1818.0]]}, {"text": "may still not generalize to other datasets or languages.", "confidence": 0.9915239214897156, "text_region": [[299.0, 1832.0], [1630.0, 1834.0], [1630.0, 1880.0], [299.0, 1878.0]]}], "img_idx": 0}
{"type": "text", "bbox": [1870, 3972, 3379, 4309], "res": [{"text": "Wethankthereviewers", "confidence": 0.9918308258056641, "text_region": [[1944.0, 3981.0], [2526.0, 3987.0], [2525.0, 4017.0], [1944.0, 4011.0]]}, {"text": "comments to improve this paper. We thank Yifeng Ding foi", "confidence": 0.992106556892395, "text_region": [[1881.0, 4046.0], [3365.0, 4046.0], [3365.0, 4097.0], [1881.0, 4097.0]]}, {"text": "his helpful discussion on this work. This work was partially", "confidence": 0.9882510900497437, "text_region": [[1879.0, 4113.0], [3366.0, 4113.0], [3366.0, 4165.0], [1879.0, 4165.0]]}, {"text": "supported by NSF grants CCF-2131943, and CCF-2141474.", "confidence": 0.9904772043228149, "text_region": [[1879.0, 4190.0], [3369.0, 4184.0], [3370.0, 4234.0], [1880.0, 4240.0]]}, {"text": "We also acknowledge support from Kwai Inc. and Ant Group", "confidence": 0.9957823157310486, "text_region": [[1881.0, 4252.0], [3362.0, 4255.0], [3362.0, 4302.0], [1881.0, 4298.0]]}], "img_idx": 0}
{"type": "text", "bbox": [552, 1970, 1533, 2015], "res": [], "img_idx": 0}
{"type": "title", "bbox": [2345, 3861, 2908, 3904], "res": [], "img_idx": 0}
{"type": "title", "bbox": [2374, 2315, 2878, 2361], "res": [], "img_idx": 0}
